{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def combine_text_files(directory):\n",
    "    combined_string = \"\"\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file is a text file\n",
    "        if filename.endswith(\".txt.clean\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            \n",
    "            # Open and read the file\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                combined_string += file.read() + \"\\n\"  # Add a newline after each file's content\n",
    "\n",
    "    return combined_string\n",
    "\n",
    "combine_text_files = combine_text_files('../storage/corpus/')\n",
    "\n",
    "with open('../storage/corpus/complete_corpus.txt', 'w', encoding='utf-8') as output:\n",
    "        output.write(combine_text_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Mixed Document Formatting**\n",
    "\n",
    "Inconsistent document formatting can impact the pre-processing phase. Pre-processing is important for generating reliable embeddings and subsequent search queries. When the text contains irregular spacing, truncated paragraphs, and non-standard date formats, there can be errors in errors in tokenization, sentence segmentation, and the overall embedding process:\n",
    "\n",
    "-   **Tokenization Issues**: Inconsistent spacing and formatting can confuse the tokenization process where text is split into words or subwords. For instance, the phrase \"October 30,1735 July 4, 1826\" might be incorrectly tokenized, resulting in poor quality embeddings. If the tokenization fails, the model might generate embeddings that do not accurately reflect the content, leading to irrelevant or incorrect search results.\n",
    "-   **Sentence Segmentation**: The model relies on clear sentence boundaries to generate accurate embeddings. Consider for example: \"Adams, a sponsor of the American Revolution in Massachusetts, was a driving force for independence in 1776; Jefferson called him the 'Colossus of Independence'.\" The semicolon here could be misinterpreted as a sentence boundary, leading to fragmented embeddings and poor information retrieval.\n",
    "-   **Date and Number Parsing**: Non-standard date formats and number representations can also lead to errors in understanding the timeline of events. For example, the format \"1797 1801\" without clear punctuation might be misinterpreted by the model, affecting its understanding of historical sequences or the retrieval of date-specific information.\n",
    "\n",
    "In order to mitigate for these problems, we can consider:\n",
    "\n",
    "-   **Preprocessing Normalization**: The system could implement text normalization during preprocessing to standardize spacing, punctuation, and date formats. This could involve using regular expressions to correct common formatting issues before tokenization.\n",
    "-   **Advanced Tokenization Techniques**: The system can use advanced tokenization techniques that can handle irregular spacing and formatting, such as subword tokenization or specialized tokenizers designed for historical texts.\n",
    "-   **Contextual Embedding Models**: The system can employ models that can better understand context even with formatting issues, such as transformers with pre-trained contextual embeddings that are less sensitive to minor formatting variations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Inconsistent Date Formats: 14\n",
      "Total Spacing Issues: 1524\n"
     ]
    }
   ],
   "source": [
    "with open(\"../storage/corpus/complete_corpus.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    corpus = file.read()\n",
    "\n",
    "# Inconsistent date formats\n",
    "date_pattern = re.compile(r'\\b\\d{4}\\s+\\d{4}\\b')\n",
    "inconsistent_dates = date_pattern.findall(corpus)\n",
    "\n",
    "# Spacing issues\n",
    "spacing_issues = re.findall(r'\\s{2,}', corpus)\n",
    "total_spacing_issues = len(spacing_issues)\n",
    "\n",
    "print(f\"Total Inconsistent Date Formats: {len(inconsistent_dates)}\")\n",
    "print(f\"Total Spacing Issues: {total_spacing_issues}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Character and Named Entity Recognition (NER)**\n",
    "\n",
    "The corpus contains numerous references to historical figures and events, making accurate Named Entity Recognition (NER) crucial for the model's ability to retrieve and generate relevant answers. Misidentifying or failing to recognize entities like \"John Adams\" or \"Thomas Jefferson\" could lead to incorrect or misleading information being retrieved, which would be particularly problematic given the domain-specific and institution-specific focus of the system. Here are some issues worth considering:\n",
    "\n",
    "-   **Disambiguation of Common Names**: Names like \"John Adams\" or \"Thomas Jefferson\" could refer to multiple individuals within different contexts. Without proper NER, the model might confuse these entities, leading to errors in information retrieval. For example, \"John Adams\" could refer to the second President of the United States or another historical figure with the same name, depending on the context.\n",
    "-   **Historical Context**: Many entities in the corpus are tied to specific historical events. Accurate recognition of these entities is essential for understanding the context of a query. For example, understanding that \"Colossus of Independence\" refers to John Adams and his role in the American Revolution is critical for accurate retrieval.\n",
    "-   **Complex Entity Relationships**: The corpus features complex relationships between entities, such as family connections (e.g., \"John Adams\" and \"John Quincy Adams\") and political affiliations. The model needs to correctly recognize these relationships to provide accurate and contextually relevant answers.\n",
    "\n",
    "In order to mitigate for these problems, we can consider:\n",
    "\n",
    "-   **Advanced NER Models**: The system can utilize state-of-the-art NER models, such as BERT-based NER or custom-trained models on similar historical text corpora, to improve the accuracy of entity recognition.\n",
    "-   **Entity Linking**: The system could implement an entity linking system that can disambiguate entities based on context. For instance, linking \"John Adams\" to his role as the second U.S. President rather than another individual with the same name.\n",
    "-   **Contextual Embeddings**: Use contextual embeddings that can capture the nuances of the relationships between entities and their historical significance. This would help in maintaining the context and providing accurate, relevant information in response to queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Entities and Their Frequencies:\n",
      "United States: 122\n",
      "New York: 110\n",
      "White House: 58\n",
      "Theodore Roosevelt: 45\n",
      "Abraham Lincoln: 34\n",
      "Vice President: 30\n",
      "Republican Party: 27\n",
      "John Adams: 23\n",
      "Woodrow Wilson: 20\n",
      "Supreme Court: 19\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Named entity pattern\n",
    "entity_pattern = re.compile(r'\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b')\n",
    "entities = entity_pattern.findall(corpus)\n",
    "\n",
    "# Count the frequency of entities\n",
    "entity_counts = Counter(entities)\n",
    "common_entities = entity_counts.most_common(10)\n",
    "\n",
    "print(\"Top 10 Entities and Their Frequencies:\")\n",
    "for entity, count in common_entities:\n",
    "    print(f\"{entity}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By addressing these two critical issues, the system can significantly improve its ability to accurately retrieve and generate relevant answers, particularly in a domain-specific context where precision is paramount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vs_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
