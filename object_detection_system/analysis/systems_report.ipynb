{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Design Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Overview\n",
    "\n",
    "The object detection system for the logistics company is designed to process video streams, detect objects, and provide various services through a Flask API. The system meets the requirements for processing videos, handling UDP streams, storing detection results, and managing hard negatives.\n",
    "\n",
    "#### System Components and Processes\n",
    "\n",
    "1.  **Data Collection**:\n",
    "    \n",
    "    -   Video streams from webcams, processed in real-time using UDP protocol.\n",
    "2.  **Data Preprocessing**:\n",
    "    \n",
    "    -   Frames extracted from video streams, resized, and normalized for model input.\n",
    "3.  **Object Detection**:\n",
    "    \n",
    "    -   YOLO (You Only Look Once) model used for detecting specified objects within frames.\n",
    "4.  **Post-Processing**:\n",
    "    \n",
    "    -   Non-Maximal Suppression (NMS) applied to refine detections.\n",
    "5.  **Storage**:\n",
    "    \n",
    "    -   Detected frames and their associated predictions stored in .jpg format with annotation files in YOLO format.\n",
    "6.  **Rectification**:\n",
    "    \n",
    "    -   Identifies and augments hard negatives within the dataset for quality improvement.\n",
    "7.  **API Interface**:\n",
    "    \n",
    "    -   Endpoints for video processing, listing detections, retrieving hard negatives, and serving annotated images.\n",
    "\n",
    "A diagram of the system has been provided as part of the class lectures, please find below. It can also be found in slide 13 of Object_Detection_System_release.pptx (in the course materials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"diagram.png\" width=\"1630.5\" height=\"648\" />\n",
    "If the image does not display, it can be found in analysis/diagram.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data, Data Pipelines, and Model\n",
    "\n",
    "#### Data\n",
    "\n",
    "The primary data sources are video streams from webcams in the logistics environment. The system processes these streams to extract frames and perform object detection.\n",
    "\n",
    "#### Data Pipelines\n",
    "\n",
    "1.  **Frame Extraction**:\n",
    "    \n",
    "    -   Video streams are captured using the `VideoProcessing` class. Frames are extracted at regular intervals, defined by the `skip_every_frame` parameter.\n",
    "2.  **Preprocessing**:\n",
    "    \n",
    "    -   Frames are resized to 416x416 pixels and normalized using the `resize_image` and `scale_image` methods in the `VideoProcessing` class.\n",
    "3.  **Object Detection**:\n",
    "    \n",
    "    -   The YOLO model, implemented in `YOLOObjectDetector`, processes each frame to detect objects. Predictions include bounding boxes, class IDs, and confidence scores.\n",
    "4.  **Post-Processing**:\n",
    "    \n",
    "    -   Non-Maximal Suppression (NMS) is applied using the `NMS` class to filter overlapping bounding boxes and refine detections.\n",
    "5.  **Storage**:\n",
    "    \n",
    "    -   Frames with detections are saved as .jpg images, and associated predictions are stored in text files using the YOLO format.\n",
    "6.  **Rectification**:\n",
    "    \n",
    "    -   The `HardNegativeMiner` class identifies hard negatives (misclassified or missed detections) and performs data augmentation (flipping, rotating, adding noise) to improve model robustness.\n",
    "\n",
    "#### Model\n",
    "\n",
    "The YOLO (You Only Look Once) model is chosen for its efficiency in real-time object detection. It balances speed and accuracy, making it suitable for dynamic logistics environments.\n",
    "\n",
    "The actual system diagram was provided as part of the lectures for this project. Find below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Definition\n",
    "\n",
    "#### Offline Metrics (Implemented in NMS)\n",
    "\n",
    "1.  **Intersection over Union (IoU)**:\n",
    "    \n",
    "    -   Measures the overlap between the predicted bounding box and the ground truth bounding box.\n",
    "    -   IoU = Area of OverlapArea of Union \n",
    "    -   $\\text{IoU} = \\frac{\\text{Area of Overlap}}{\\text{Area of Union}}$\n",
    "    -   IoU = Area of UnionArea of Overlapâ€‹\n",
    "2.  **Precision**:\n",
    "    \n",
    "    -   Measures the accuracy of the positive detections.\n",
    "    -   Precision is calculated as the number of true positive detections divided by the total number of positive detections (true positives + false positives).\n",
    "    -   Precision=True PositivesTrue Positives+False Positives\n",
    "    -   $\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$\n",
    "\n",
    "3.  **Recall**:\n",
    "    \n",
    "    -   Measures the ability to detect all relevant objects.\n",
    "    -   Recall is calculated as the number of true positive detections divided by the total number of relevant detections (true positives + false negatives).\n",
    "    -   $\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$\n",
    "\n",
    "4.  **False Positive Rate (FPR)**:\n",
    "    \n",
    "    -   Measures the proportion of false positives among the total negative cases.\n",
    "    -   $\\text{FPR} = \\frac{\\text{False Positives}}{\\text{False Positives} + \\text{True Negatives}}$\n",
    "\n",
    "5.  **Average Precision (AP)**:\n",
    "    \n",
    "    -   Measures the average precision for each class over all IoU thresholds.\n",
    "    -   AP is the area under the precision-recall curve.\n",
    "\n",
    "#### Online Metrics\n",
    "\n",
    "1.  **Latency**:    \n",
    "    -   Measures the time taken to process each frame.\n",
    "    -   Ensures real-time performance of the system.\n",
    "\n",
    "2.  **Throughput**:    \n",
    "    -   Number of frames processed per second.\n",
    "    -   Indicates the system's capacity to handle high video stream volumes.\n",
    "\n",
    "3.  **Detection Accuracy**:    \n",
    "    -   Real-time measure of the correctness of detections.\n",
    "    -   Validates the system's performance in operational settings.\n",
    "4.  **System Uptime**:\n",
    "    \n",
    "    -   Percentage of time the system is operational.\n",
    "    -   Ensures reliability and availability of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-deployment Policies\n",
    "\n",
    "#### Monitoring and Maintenance Plan\n",
    "\n",
    "1.  **Real-time Monitoring**:\n",
    "    \n",
    "    -   Implement dashboards to monitor system performance metrics (latency, throughput, detection accuracy).\n",
    "    -   Use tools like Prometheus and Grafana for comprehensive monitoring.\n",
    "2.  **Scheduled Maintenance**:\n",
    "    \n",
    "    -   Regularly update the model and system components to incorporate the latest improvements and fix bugs.\n",
    "    -   Perform routine checks and updates during low-traffic periods.\n",
    "3.  **Logging and Alerts**:\n",
    "    \n",
    "    -   Set up logging for all system activities and errors.\n",
    "    -   Configure alerts for critical issues (e.g., detection failures, system downtime).\n",
    "\n",
    "#### Fault Mitigation Strategies\n",
    "\n",
    "1.  **Redundancy**:\n",
    "    \n",
    "    -   Implement redundant systems to ensure continuous operation in case of a failure.\n",
    "    -   Use load balancers to distribute the load across multiple instances.\n",
    "2.  **Graceful Degradation**:\n",
    "    \n",
    "    -   Ensure the system can operate at reduced capacity if some components fail.\n",
    "    -   Prioritize critical functions to maintain essential operations.\n",
    "3.  **Error Handling**:\n",
    "    \n",
    "    -   Implement robust error handling to manage and recover from unexpected failures.\n",
    "    -   Use try-except blocks and proper exception handling in the code.\n",
    "4.  **Regular Backups**:\n",
    "    \n",
    "    -   Schedule regular backups of data and system configurations.\n",
    "    -   Store backups in secure, off-site locations for quick recovery."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
